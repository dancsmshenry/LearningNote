- 内核页表一般指的是内核地址空间的页表，用户页表表示用户地址空间的
  - 用32位操作系统作为例子，虽然操作系统有N个进程，每个进程都有各自页表，但内核的页表只有一个。当发生进程切换时，只有用户页表被切换走，内核页表并不改变
  - 具体的做法是，把地址空间的高1G或者2G的地址都固定划分给内核，用户进程只能使用低3G或者低2G的地址，这样无论进程如何切换，内核页表都不需要换出



- 页表都是在内存空间中的（保证用户无法修改）
- 至于访问页表是否会陷入内核态
  - CPU地址翻译的过程中的页表访问，CPU地址翻译，这种访问是硬件完成的，整个过程不需要代码参与，没有任何性能上的损失
  - 第二种，是慢一点，是陷入内核态的
    - 这种慢是为了安全，如果页表在用户空间，那么用户就可能自己修改页表，映射任意的内存地址，访问任何内存，甚至是直接操作硬件，进程间、内核的隔离保护就失去了意义
    - 而且，应用程序虽然可能频繁的malloc或者free，但在页表层面上，并不会频繁的创建、删除页表项，主要原因是，malloc/free操作的接口都是C库的接口，在C库里，还有另外一层次的封装，来保证不会频繁的提交页表的操作申请



- 即，每个进程都有一个页表，两个不同的进程的内核页表项指向相同的物理地址



- 而且，应用程序虽然可能频繁的malloc或者free，但在页表层面上，并不会频繁的创建、删除页表项，主要原因是，malloc/free操作的接口都是C库的接口，在C库里，还有另外一层次的封装，来保证不会频繁的提交页表的操作申请



- 页表保护的是进程的虚拟地址空间，这包括内核空间也包括用户空间。不同进程的内核地址空间一致的，但是页表也保护了内核地址空间免于被用户态程序访问。

  页表表现为一段内存里的数据，每个进程不同。他由内核管理，即内核可以修改页表的内容。但是是由CPU的硬件访问的，CPU的在遇到访存指令cache miss时访问页表，具体由mmu执行访问，因为是硬件访问，所以不涉及陷入内核的问题。

  访问页表的确会拖慢CPU速度，所以CPU内有tlb，叫做快表来缓存一部分页表条目，以加快查表速度。tlb的作用与cache类似。

  

  印象里内核页表和用户态页表是一张表。只不过各个进程的内核部分是相同的。



- 我的一个理解：
  - 页表是分为内核页表和进程页表的
  - 进程切换的时候，改变的是进程页表
  - 进程页表中分别映射着内核空间和用户空间，其中内核空间就是内核页表的一个复制
  - 一般我们对页表的访问，是通过硬件实现的，所以就没有陷入内核态？（硬件即mmu+tlb）
  - 页表都是存放在内核空间的，因为是为了防止用户去修改页表的内容
  - 所有进程的内核空间页表都是一样的，只是用户空间的页表不同



- 你以为在用户进程中分配内存的时候，就马上通过系统调用陷入内核，然后进行页表操作吗？内核如今已经发展的很成熟了，当然不会这么傻。在你兴高采烈的分配好一块内存后，内核只是给你找了一块独一无二的虚拟内存空间，并没有映射到物理内存，所以根本没有页表的操作。只有你真正用到你的内存时，MMU发现无法进行虚拟内存到物理内存的转换，只好抛出page fault异常，然后进入内核进行物理内存的分配过程，接着就给你把页表创建好了，这个整个过程叫做惰性分配。更重要的是，其实libc库在进程创建的时候，就已经把堆空间用内存池的方式管理起来，在进程分配小于128kb的内存时，根本不需要内核进行任何操作，因为堆这个段的虚拟内存早就映射好了物理内存，何谈效率的影响？