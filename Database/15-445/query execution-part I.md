# processing model

- 执行模型，执行计划是如何计算的
- 规定了系统是如何执行查询计划的
- 根据不同的工作负载，有不同的权衡



## approach 1 iterator model

- 火山模型（迭代器模型），也叫做pipeline流式模型
- 每个算子都要实现一个next()方法
- 每次父算子会调用该算子的next()方法，当前算子就要向父算子返回数据
- 如果当前算子也是一个父算子的话，就要循环的调用子算子的next方法，得到下一层的数据
- <img src="image/iterator model_01.png" style="zoom:200%;" />

- 循环的调用下面算子的next（）让它返回一些可用的数据，然后再对其进行操作

- ```python
  for t in child.Next():
      emit(projection(t))
  #	循环的调用子算子的next函数，利用它返回的数据，进行下面的操作
  ```

- ![](image/iterator model_02.png)

  - 这里有一个问题就是，算子的循环，其实是通过不断的调用next函数，得到其返回值再进行下一步的
  - 就比如这里，编号1的算子就会因为编号3和编号2的查询而阻塞，因为只有下面的算子返回了数据，上面的算子才能继续下去
  - 而且，它这里并不是一次性返回所有的数据，而是你调用了next它才会返回的
  - 再比如说这里的编号2的join过程，因为join返回的数据是要把这两条语句全部给执行一遍，所以编号1算法需要一直阻塞，知道编号2全部执行完了，才会继续下去



- 几乎所有的DBMS都用到了火山模型
- 一条条数据向上吐出，和直观上的感受是不一样的（直观上认为是把所有的数据都计算好，再往上返回；这是后面一种模型）
- 存在一些算子有block的阶段（比如join subqueries order by，这些算子都要把所有的数据得到才能返回）
- 在一些情况下比较有用（比如说limit 100，只需要在最上面控制输出的数量即可）
- 缺点：阻塞问题；每一条数据的传输都是依靠函数调用，有可能会函数栈溢出（影响性能）





## approach 2 materialization model

- 物化模型
- 就是比较符合一般的认识的一种做法，即将数据全部都算出来（全部都获取到），才返回给上一级
- 每一级都有一个out数组，把得到的数据计算好后放到out数组中，然后返回给上一层的算子
- ![](image/materialization model_01.png)
- 所有的算子都只调用一次
- 一些偏向OLTP的数据库，比如交易的数据库会使用这种数据库
  - 因为涉及交易的操作很多都是点查询，只涉及很少的数据
  - 即每次得到的结果都很少，数据库都能够负载的了






## approach 3 vectorized/batch model

- 向量化模型（分批模型）
- 属于是方法一和方法二的中间派，就是两种方法的结合
- 像火山模型一样有next方法，但是返回的不是一条数据，而是一批数据
- 适用于OLAP类型的数据库
  - 因为既能使得中间的结果集不太大，又能使得函数的调用次数相对少一点
- 优点：
  - 背景：intel有一个能够同时处理多个数据的指令（即在一个机器指令的周期就能够将数据全部计算好）
  - 而这种方法就可以利用这种指令，同时传入多个数据进行处理
  - 向量执行模型（avx-512）


 

## plan processing direction

- 方法一：top to bottom
  - 从上往下执行，从根节点去下面拉去数据
- 方法二：bottom to top
  - 从叶子结点开始执行
- 是指函数调用的方向（是从根节点的函数往下调用，还是从叶子结点的函数往上调用）





# access methods

- 选取数据，接受数据的方法
- 读取表中的数据有哪些方法



## sequential scan（顺序扫描）

- 从磁盘中把数据页放到内存中，每条记录每条记录的扫描遍历

- ```python
  for page in table.pages:
      for t in page.tuples:
          if evalPred(t):
              #	do something
  ```

- 说白了就是全表遍历

- 即如果需要某页，就现在buffer pool中去找，如果有的话，就把它遍历；否则就去硬盘中去找

- 执行过程中的算子需要保持一个指针，把这个指针当作迭代器一样去扫描遍历数据



### optimizations(优化)

背景：类似全表扫描等操作，存在很多优化的可能

方法一：prefetching

- 提前将数据从磁盘中预先取出来

方法二：buffer pool bypass

- 因为是全表扫描，用过的数据就不会再用上了，所以就不用将数组再存储在buffer中了，而是用完后就丢掉

方法三：parallelization

- 并行执行，即可以起两个线程，一个线程从前扫到中间，另一个线程从中间扫到后面
- 即并发的算子多线程执行

方法四：zone maps

- 背景：假设有一个需求，要扫描大于100的数据值，但是呢，当前页的全部值都小于100，如果把页放到内存中，会很浪费
- 所以希望用一个map，用来**记录关于这个页**的相关信息（比如说max，min，avg，sum等），以便DBMS筛选掉某些页
- ![](image/zone maps.png)
  - 缺点：浪费空间；不好存放（如果存放到每个页中的话，那么读取zone map的时候就会把直接把页面读到内存中，那就没啥用了...；所以需要额外的页存储每一页的map信息；如果原始数据可能发生了一点点修改，那么map可能会因此发生很大的修改）

方法五：late materialization

- 延迟物化
- 只需要把符合条件的记录的id（offsets）给返回，在最后返回数据的时候才将数据进行物化，减少了扫描的工作量
- 非常适用于列存储的数据库，因为算子一般只对列的数据进行处理
- 即主要适用于优化在列数据库中



## index scan（单索引扫描）

- 查询扫描走索引的一些条件：（主要在十三章有讲）
  - 索引有没有我们需要的属性
  - 索引是否含有我们需要的输出列
  - 索引的值域
  - 谓词的压缩
  - 是否为唯一索引
- 加入有两个索引，应该选择哪一个索引
  - 选择该索引后剩下的数据越少，就选那一个



## multi-index scan（多索引扫描筛选）

- 比如上面的问题，即用一个索引筛出数据A，用另一个索引筛出数据B，然后对这两个数据进行取交集
- <img src="image/multi-index scan.png" style="zoom:150%;" />
- 底层是用bitmap实现的







# modification queries

- 涉及数据的修改的语句的执行逻辑
- 对于数据的插入、更新和删除，都是要检查其是否符合数据库的约束的（比如说unique等），同时要维护数据的索引



update/delete

- 下面的算子将要删除的记录id返还给上一层，然后用这个id去删记录
- 删除算子和更新算子都要记录自己对哪些数据进行了操作



insert

- 算子内部将数据物化，将数据整个插入
- 需要子算子将行记录物化好，则当前的insert算子只要将记录插入即可



update problem

- 假设要更新一个索引上所有的数据，使其全部加上100
- 然后，update的操作是，每读一个数据就把该数据先从index中移除，然后+100，然后再放回去
- 问题就是如果你的update算子不记录自己对哪些数据进行了操作，造成的结果就是会无限的+100....
- 所以无论是update还是delete，都要记录下自己对哪些数据进行了操作
- 这被简称为halloween problem万圣节问题







# expression evaluation

- 谓词表达式的一些计算
- ![](image/expression evaluation.png)
- 一个通用的处理方案
  - ![](image/expression evaluation_01.png)

- ![](image/expression evaluation_02.png)
  - 过程：先每次去一条记录的value值，然后计算？ + 1的值是多少，最后再将二者进行比较
  - 这里的问题是每次都要计算一遍？+1的值是多少，就降低了效率
  - 所以可以预先将值先计算一遍（类似JIT，just in time，java运行的是字节码，相当于把代码编译为了字节码，而不是二进制；于是有一种思路就是，发现一些重复利用的代码，于是就将其编译成了二进制，提高效率，即再使用这类代码的时候就变为二进制执行了）
    - 把一些热点的代码段编译为二进制，从而提高效率
    - 执行的时候判断
    - 即运行的时候，将一些代码编译为二进制运行

  - AOT，执行之前就判断

- 引申到数据库就是，如果DBMS发现一些判断语句始终是相等的，那就不判断了，直接就指定为true即可



- 总结一下就是，SQL语句也类似上面的火山模型一样往下继续分解执行的
- 但是对于一些特定的场景，我们发现可以有类似jit的处理，从而提高效率

