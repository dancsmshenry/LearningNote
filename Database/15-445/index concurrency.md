# background

- 前面的操作中，都假设只有一个线程去操作数据结构，但是实际上，具体的场景下是有多个线程操作数据库的
- 所以要研究如何多线程安全的执行查询
- 达到线程安全的同时，也要注意如何优化磁盘IO
- PS：也有一些单线程的数据库，比如redis，只支持单线程去操作，一个用户操作完，别的用户才能进去
  - redis高效，有一部分是因为不需要考虑多线程并发的问题
- 并发控制分为两种：
  - logical correctness：一个线程能够看到它应该看到的数据（事务并发设计的概念）
  - physical correctness：物理上的，数据的内部表示是否正确稳定的（本节课的重点）



# latches overview

## locks

- 指代逻辑上的锁，宏观上的锁
- 要保护数据库中逻辑上的一个内容，不被其他的线程或者事务修改
- 一般是被事务所持有
- 被修改的数据可以被回滚



## latches

- 保护的是数据库内部的一个具体的数据结构的
- 比如说上面说要锁一行数据，那么就会在那个数据结点上给一个latch
- 是被操作过程所持有的，比如插入或删除
- 比如说往B+里面放一个数字，中间的过程就会加上很多的latch
- 不需要回滚（偏向微观的一把锁）



![](image/locks vs latches.png)



## latch modes

### read mode

- 读锁，让读数据，不让写数据
- 也叫做共享锁，即S锁



### write mode

- 写锁，写数据，不能让别的线程读写数据
- 也叫做独占锁，即X锁



- ![](image/compatibility matrix.png)



## latch implementations

- 锁的实现方式



### blocking OS Mutex

- 非常好用（OS自己支持的），但是不能用于大规模竞争并发的场面
- 比如std::mutex
  - 底层实现是pthread_mutex_t，再底层就是futex
  - 就在用户态有一个flag，如果能够拿锁，就标记这个变量flag
  - 此时如果有新的线程又来拿锁，发现变量被标记了，线程就直接陷入内核态（但有点类似sleep，好处就是sleep不会大量竞争消耗系统资源）（一般的操作是让自己sleep）
  - 如果上面的线程又把锁释放了，那么OS就会唤醒上面进入内核态的线程
  - 缺点就是把线程睡眠又唤醒，这种开销是比较大的



### test and set spin latch

- spin lock，自旋锁，好处就是非常的高效，但也没办法应用于大规模的竞争，同时对操作系统的缓存也不是友好的
- 设置一个标志位latch，锁上的时候设置为1，解锁的时候设置为0
- 加锁的过程是用一个while去检测latch是否为0，如果为0就加锁，为1的话就一直死循环
- 即用户态不断的循环（latch是std::atomic<T>）
- 所以数据的实现必须是原子性的，操作系统底层支持原子操作，即修改数据的过程中，别的线程是不能参与的
- 在用户态不要用自旋锁（因为自旋锁，别的线程如果一直不释放锁，就会导致竞争的线程极度的浪费资源，因为多个线程会不断的检测这个锁有没有被解开）
- java给的一个思路就是，锁先疯狂的自旋，如果超过一定的时间，就会陷入内核态



### read-write latches

- 但是不能作为锁的一种实现
- 就是上面说的读写锁
- 比如说此时有两个人加了读锁，那么后面第三个人如果想要加写锁，就要等前面两个人放掉读锁后才能继续写锁
- 再比如说如果此时还有人想加读锁，就不能加了，因为这里的加锁是要讲究顺序的，必须等上面的人把写锁加了，才能继续加读锁



# hash table latching

- hash是比较好加锁的，你比如说开放地址hash，如果找不到slot就会往下找，因为查找的方向永远是从上往下的，不会有死锁（B+树可能会死锁）
- 而如果要扩容的话，就要加一个全局的写锁，即global lock，因为扩容数据结构会全部改变（不在扩容阶段，可以加局部锁）



## page latches

- 比如说要查找一个数据D，那么就要给对于的slot所在的page加上一个读锁，如果当前page没有，就往下一个page去找，同时也要释放当前页面的latch
- 说白了就是对不同的page加读写锁
- java里面的ConcurrentHashMap底层就是分段hash，控制并发就是利用这种手段
- 锁的粒度不细，同时保证了一定的并发性质



## slot latches

- 按照slot（槽）进行加读写锁
- 即上面是以page为单位加锁，这里是以slot为单位加锁
- 粒度变得更加的细致了，更加能够避免并发冲突
- 缺点：要维护太多太多的锁了，大多数的场景是无法承受的



- go里面的map是不支持并发的，sync.map才是支持并发的
- 读写分离，主的hashtable是只读的，副的hashtable是用来写的，写的完后定期的把它刷到主的hashtable上
- 好处：读的时候是无锁的



## compare and swap

- 无锁的hashtable
- __sync_bool_compare_and_swap(&M,20,30)
  - M是操作的变量的地址
  - 20是原来这个变量上的值
  - 30是我想要改为后得到的值
  - 语义就是把M变量的值改为30
  - 实际操作就是先让OS看看当前的M是不是20，如果是20的话就要把它锁住，然后把它改为30
  - 先比较，在交换设置，借此解决并发问题
  - 这是一个原子的操作
  - 给定原值就保证了线程之间是没有冲突的
  - 返回的是true或false
- ![](image/compare and swap.png)
- 如果不想加锁的话，这也是一种解决方案
- 缺点：只会告诉你是否失败，但如果失败了的话就要自旋的去操作
- hashtable插入值的时候可以这样做

 



# b+tree latching

- 为了多线程的读写B+树
- 需求：
  - 一：要保护结点内部的数据，不能让多线程同时的修改数据
  - 二：结点和结点之间会有合并的操作，page之间的合并，也不能让多线程同时去操作

- 比如说要删除44，那么删除后发现要合并页，但是此时有人要查询41，去到原本41的位置的时候，发现没有（因为此时页数发生了合并，数据跑到另一页了..）



## latch crabbing/coupling

- 著名的螃蟹协议
- 先获取根节点的锁，如果发现数据在左子树，就先把左子树结点的数据上锁
- 然后再判断锁上了左子树后，根节点能不能解锁，如果能解锁就解锁
- 然后再从左子树找它的子树，依次循环这样
- 问题：这么判断能不能解锁，解答：即下面的split和merge不会影响树的结构，即下面的结点会不会触发分页或者合并（因为分页或者合并就会触发指针）
- find
  - 先锁上孩子结点的锁
  - 然后把父节点解开
  - 所以如果只是读的话，就像螃蟹一样一直往下走
- insert/delete
  - 先锁上孩子结点的锁
  - 但是要判断孩子结点是不是一个安全的结点，如果不安全就不能放锁；安全的话就可以解锁
  - 这里的安全应该是说不会触发分页或者合并
- 从38min开始都是举例crabbing的，一直到43min
- 但是发现，每次无论上面操作都要先锁根节点，所以根节点就变为了瓶颈
  - 发现这种是一个悲观的心态
  - 而绝大部分的操作其实是不会引起根节点的变化，所以不一定一上来就加锁
- 一种乐观加锁的方式
  - search不变
  - insert/delete的时候，加的是读锁（因为你加写锁，所有的人都不能看这个树了...）
  - 一路读锁，到真正要操作的时候，才把读锁升级为写锁
  - 但是也有不好的地方，你比如说children结点导致了parent结点也要改，那么只能推导重来，从根节点重新给它加写锁
  - 而这种方案，赌的就是绝大部分的操作是不会对上层的索引有修改，就大部分的操作只会修改叶子结点，不会修改上层的结点
  - 一旦发生了修改上层结点，就回滚
- 不管悲观还是乐观，锁都是从头往尾加的
  - 所以说，如果你加锁的过程中，给children加锁的时候发现加不了锁，就只能等待了
- 而B+树厉害的地方就是可以遍历加锁





# leaf node scans

- 因为B+树是可以支持范围搜索的，即比如说find keys > 4，那么就直接找到4的位置，然后用下面的链表从左往右开始遍历，一边遍历一遍加锁
- 可是呢，如果加的是读锁，就没事，如果加的是写锁，那么就可能会出现死锁的情况
- 比如说又有一个update keys < 10，那么就可能会先锁住key为9的数据，那么就会出现，find keys > 4 拿着key为5的锁，要争夺key为9的锁，update keys < 10拿着key为9的锁，要争夺key为5的锁
- 就会有死锁
- 可惜B+树的latch天生不支持死锁检测
- 解决办法：只允许往一个方向走，比如说只允许find keys > 4这个方向，不能反方向查询
- 但又想要倒序的遍历，解决办法就是倒序索引，就反方向的构建一遍索引
- 所以对于B+树的索引，要添加一些规则进去





# conclusion

- 让一个数据结构实现线程安全，是非常困难的
- 在B+树上用的技巧，也可以用在其他的数据结构上的，例如skip list