# backround

- 前面的分析都是基于事务已经发生了，然后再去判断分析是否可行
- 而实际上是不可能这么顺利的...
  - 有点马后炮的意思..

- 实际上我们是不知道整个事务是怎么允许的
- 所以需要用锁实现对数据的保护







# lock types

latches

- 保护的是底层的数据结构（比如说B+树，hash表）
- 微观的概念
- 物理的结构结构，hash的数据，树的结点



lock

- 对数据库的抽象的内容的锁
- 宏观的概念
- 即对于用户来说，是获取一条数据的lock，而真正去操作这条数据的时候，即到B+树上的时候，才会去操作latches
- 锁的是表，锁的是行
- lock的类型
  - S-LOCK：shared lock，共享锁，读锁
  - X-LOCK：exclusive lock，排他锁，写锁
- 锁的过程
  - 事务需要锁
  - 锁管理器要么给锁（锁是空闲的）要么阻塞（锁给其他事务了）
  - 事务释放锁
  - 锁管理器更新锁的情况





# two-phase locking

- 把锁用在并发控制中，决定了一个事务在运行过程中如何和其他的事务进行协调
- 不需要知道提前知道事务做了什么
- 2PL是针对单个事务来说的
- 阶段一：growing
  - 本事务只能不断的加锁，不能解锁
- 阶段二：shrinking
  - 本事务只能解锁，不能加锁
- 如果加锁的过程中，发现锁已经被别人拿走了，于是就会被阻塞，直到锁被释放的时候才能拿到锁
- 用二阶段锁的事务执行顺序，用依赖图表示是没有环的
- 普通的二阶段锁会出现级联终止的问题（P27）
  - 即事务A先做一部分，事务B基于事务A的数据再做一部分，结果事务A要回滚了，导致事务B出现了错误
  - 问题就在于事务B是在一个临时版本操作的
- 一种解法：最后commit的时候才释放锁（就是严格的二阶段锁了）



- 2PL存在脏读
  - 就是上面级联终止的情况
- 解决办法：严格二阶段锁（strong strict 2PL）（SSTPL）
  - 原来的二阶段锁，在shrinking的时候，是可以边操作边解锁的
  - 一定程度后锁的数量会保持不变
  - 到了最后事务commit的时候才会释放所有的锁
  - 事务修改的数据，一直到事务提交之前，别人都不能修改
- 好处：不会出现级联回滚；事务中间可能对数据又多次操作，但是不用管，直接回滚到事务之前的版本即可







# deadlocking detection + prevention

- 无论是2PL，还是严格2PL，都可能会产生死锁饥饿
- 解决办法：
  - deadlock detection（死锁检测）
  - deadlock prevention（死锁预防）



## deadlock detection

- 内部会维护一个锁依赖图，记录了当前并发的事务谁在等待谁的锁，图的每个结点都是一个事务
- 事务A指向事务B，表示事务A在等待事务B的锁
- 周期性的去检测锁依赖图
- 发现环的话，就选择一个事务回滚，解开环，使得事务跑下去
- 一个权衡：因为是周期性的检查图，所以要权衡检查维护的频率
- 应该选择哪一个事务进行回滚：
  - 考虑的因素：如果执行了时间特别的长或者快要执行完了的，就不要干掉他
  - 看事务执行了多少条sql语句，即查看要回滚的代价，尽量干掉sql语句做得少的事务
  - 查看事务拿了多少锁，要干掉加锁加的多的事务
  - 考虑多少其他的事务都因为它而回滚过（即检测该事务被回滚了多少次）
- 回滚的方法：要么完全回滚；要么部分回滚



## deadlock prevention

- 根据时间戳给事务优先级，越先开始的事务有高优先级
- old waits young，如果是老的事务（高优先级）想要加锁，发现锁被一个年轻的事务拿到了，那么老的事务就要等年轻的事务释放了才能拿
  - 反之，年轻的事务想要加的锁在老的事务持有，那么年轻的事务就要abort
- young waits for old，如果一个老的事务想要拿的锁被一个年轻的事务持有，那么老的事务就把年轻的事务的锁抢过来，并把年轻的事务abort
  - 反之，年轻的事务想要加的锁在老的事务持有，那么年轻的事务要等待老的事务

- 说白了就是给事务优先级，然后针对优先级指定不同的策略，即高低有顺序（这就是为什么可以解决死锁的原因，有点像swap时，要先拿低地址数据的lock，再拿高地址数据的lock一样，就要保持所有的拿锁都有一个顺序可言）
- 被abort的事务的时间戳是多少：应该还是原来的时间戳（为了防止饥饿，因为此时年轻的时间戳，早晚会变成老的时间戳）
- mysql的死锁检测是第一种，old waits young





# lock granularitiles

- 锁的粒度

- 如果更新两条事务都要锁表的话，并发粒度就会下降
- 想要更少的锁的数量，还是要用更大粒度的锁
- 大粒度的锁：给整个表加锁，要先检查每个行是否要加锁
  - solve：给一个标记，加行锁的时候标记一下，表示当前加不了表锁了



## intention lock

- 意向锁

- 只是一个意向标记
- 如果一个表被加了意向锁，就表示下面的行被加锁了
- intention shared（IS）下面的行有被加S锁，意向共享锁
- intention exclusive（IX）下面的行有被加X锁，意向排他锁
- shared + intention -  exclusive （某些行被加了排他锁，整个表又被加了共享锁）即共享锁锁了整个表，但是有用排他锁锁了下面的行
- 有个锁兼容矩阵



## locking protocol

- 想要对一个行加s锁，就要对表加IS锁
- 想要对行加X锁，IX，SIX，则表要加IX锁



- 动态加锁，锁的粒度需要升级
- 如果底层加锁太多的话，就要加为表锁



- 绝大部分锁，都是DBMS自己加的
- 而DBMS也提供了接口，让用户可以在语法上加锁
  - LOCK TABLE <table> IN <mode> MODE;
  - select * from <table> where <> for update;（数据库备份的时候用到的）
  - 显式告诉数据读的数据要加的不是共享锁，而是排他锁





# conclusion

- 几乎所有的关系数据库都用了2PL
- 例如MYSQL,PG（pg有些还有个ssi）

- 通过2PL可以放心的让事务进行并发